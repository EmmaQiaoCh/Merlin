{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3403a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 NVIDIA Corporation. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03166488-1651-4025-84ed-4e9e5db34933",
   "metadata": {},
   "source": [
    "# Building Intelligent Recommender Systems with Merlin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9657308-2e08-49b4-8924-eace75a4634c",
   "metadata": {},
   "source": [
    "Recommender Systems (RecSys) are the engine of the modern internet and the catalyst for human decisions. Building a recommendation system is challenging because it requires multiple stages (data preprocessing, offline training, item retrieval, filtering, ranking, ordering, etc.) to work together seamlessly and efficiently. The biggest challenges for new practitioners are the lack of understanding around what RecSys look like in the real world, and the gap between examples of simple models and a production-ready end-to-end recommender systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405280b0-3d48-43b6-ab95-d29be7a43e9e",
   "metadata": {},
   "source": [
    "The figure below represents four-stage recommender systems. This is a much more complex than only training a single model and deploying it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27220153",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<img src=\"../images/fourstages.png\"  width=\"70%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b21634-ab05-4790-b09c-05170772825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Learning objectives\n",
    "- Understanding four stage of recommender systems\n",
    "- Training retrieval and ranking recommender system models with Merlin Models\n",
    "- Deploying trained models to Triton Inference Server with Merlin Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b7f3bd",
   "metadata": {},
   "source": [
    "## Feature Engineering with NVTabular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e240fdd",
   "metadata": {},
   "source": [
    "In this example notebook, we use the [Ali-CCP: Alibaba Click and Conversion Prediction](https://tianchi.aliyun.com/dataset/dataDetail?dataId=408#1) dataset to build our recommender system models. Below, we will process input features with [NVTabular](https://github.com/NVIDIA-Merlin/NVTabular)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cdbfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvtabular/nvtabular/graph.py:23: FutureWarning: The `nvtabular.graph` module has moved to `merlin.dag`. Support for importing from `nvtabular.graph` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.dag`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/io.py:23: FutureWarning: The `nvtabular.io` module has moved to `merlin.io`. Support for importing from `nvtabular.io` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.io`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/utils.py:23: FutureWarning: The `nvtabular.utils` module has moved to `merlin.core.utils`. Support for importing from `nvtabular.utils` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.utils`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/dispatch.py:23: FutureWarning: The `nvtabular.dispatch` module has moved to `merlin.core.dispatch`. Support for importing from `nvtabular.dispatch` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.dispatch`.\n",
      "  warnings.warn(\n",
      "2022-03-24 18:34:27.228183: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-24 18:34:28.339122: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:214] Using CUDA malloc Async allocator for GPU: 0\n",
      "2022-03-24 18:34:28.339256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"]=\"cuda_malloc_async\"\n",
    "import cudf\n",
    "import glob\n",
    "import gc\n",
    "\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "from example_utils import workflow_fit_transform\n",
    "\n",
    "from merlin.schema.tags import Tags\n",
    "from merlin.schema import Schema\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "import merlin.models.tf.dataset as tf_dataloader\n",
    "\n",
    "from merlin.io.dataset import Dataset\n",
    "from merlin.schema.io.tensorflow_metadata import TensorflowMetadata\n",
    "from merlin.models.tf.blocks.core.aggregation import CosineSimilarity\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baad8ae3",
   "metadata": {},
   "source": [
    "First, we define our input and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81ddb370",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/workspace/data/train/*.parquet'\n",
    "test_path = '/workspace/data/test/*.parquet'\n",
    "output_path = '/workspace/processed/ranking'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06592024",
   "metadata": {},
   "source": [
    "<a id=\"etl\"></a>\n",
    "ETL Workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "550d45c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18.3 s, sys: 19.8 s, total: 38.2 s\n",
      "Wall time: 40.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "user_id = [\"user_id\"] >> AddMetadata(tags=[Tags.USER_ID, Tags.USER]) >> Categorify()\n",
    "item_id = [\"item_id\"] >> AddMetadata(tags=[Tags.ITEM_ID, Tags.ITEM]) >> Categorify()\n",
    "\n",
    "item_features = [\"item_category\", \"item_shop\", \"item_brand\"] >> AddMetadata(tags=[Tags.ITEM]) >> nvt.ops.Categorify()\n",
    "\n",
    "user_features = ['user_shops', 'user_profile', 'user_group', \n",
    "       'user_gender', 'user_age', 'user_consumption_2', 'user_is_occupied',\n",
    "       'user_geography', 'user_intentions', 'user_brands', 'user_categories'] \\\n",
    "    >> AddMetadata(tags=[Tags.USER]) >> nvt.ops.Categorify()\n",
    "\n",
    "targets = [\"click\"] >> AddMetadata(tags=[str(Tags.BINARY_CLASSIFICATION), \"target\"])\n",
    "\n",
    "outputs = user_id+item_id+item_features+user_features+targets\n",
    "\n",
    "workflow_fit_transform(outputs, train_path, test_path, output_path, 'workflow_ranking')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160a0766",
   "metadata": {},
   "source": [
    "We will also use a util function to wrap up the workflow transform to a one line of code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16401d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Building Recommender Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f2b234",
   "metadata": {},
   "source": [
    "NVTabular exported the schema file of our processed dataset. Merlin Models library relies on a schema object that takes the input features as input and automatically builds all necessary layers to represent, normalize and aggregate input features. `schema.pbtxt` is a protobuf text file contains features metadata, including statistics about features such as cardinality, min and max values and also tags based on their characteristics and dtypes (e.g., categorical, continuous, list, item_id). The metadata information loaded from Schema and their tags are used to automatically set the parameters of Merlin models.\n",
    "\n",
    "We use the `schema` object to define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83f90a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = TensorflowMetadata.from_proto_text_file(output_path + '/train/').to_merlin_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30e4ebc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = schema.select_by_tag(Tags.TARGET).column_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f32d40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['user_id',\n",
       " 'item_id',\n",
       " 'item_category',\n",
       " 'item_shop',\n",
       " 'item_brand',\n",
       " 'user_shops',\n",
       " 'user_profile',\n",
       " 'user_group',\n",
       " 'user_gender',\n",
       " 'user_age',\n",
       " 'user_consumption_2',\n",
       " 'user_is_occupied',\n",
       " 'user_geography',\n",
       " 'user_intentions',\n",
       " 'user_brands',\n",
       " 'user_categories',\n",
       " 'click']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc0be1",
   "metadata": {},
   "source": [
    "### Initialize Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c41e4a",
   "metadata": {},
   "source": [
    "We're ready to start training, for that, we need to initialize the dataloaders. We'll use Merlin `BatchedDataset` class for reading chunks of parquet files. `BatchedDataset` asynchronously iterate through CSV or Parquet dataframes on GPU by leveraging an NVTabular `Dataset`. To read more about Merlin optimized dataloaders visit [here](https://github.com/NVIDIA-Merlin/models/blob/main/merlin/models/tf/dataset.py#L141)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a21b4704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16*1024\n",
    "train = Dataset(os.path.join(output_path + '/train/*.parquet'), part_size=\"500MB\")\n",
    "valid = Dataset(os.path.join(output_path + '/test/*.parquet'), part_size=\"500MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f52de",
   "metadata": {},
   "source": [
    "### Building a Ranking Model with DLRM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f68e26b",
   "metadata": {},
   "source": [
    "Deep Learning Recommendation Model [(DLRM)](https://arxiv.org/abs/1906.00091) architecture is a popular neural network model originally proposed by Facebook in 2019. The model was introduced as a personalization deep learning model that uses embeddings to process sparse features that represent categorical data and a multilayer perceptron (MLP) to process dense features, then interacts these features explicitly using the statistical techniques proposed in [here](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5694074). To learn more about DLRM architetcture please visit `Exploring-different-models` [notebook](https://github.com/NVIDIA-Merlin/models/blob/main/examples/Exploring-different-models.ipynb) in the Merlin Models GH repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4325080",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.DLRMModel(\n",
    "    schema,\n",
    "    embedding_dim=64,\n",
    "    bottom_block=mm.MLPBlock([128, 64]),\n",
    "    top_block=mm.MLPBlock([128, 64, 32]),\n",
    "    prediction_tasks=mm.BinaryClassificationTask(target_column, metrics=[tf.keras.metrics.AUC()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfe2aa9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:35:10.284582: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442/2442 [==============================] - ETA: 0s - auc: 0.6461 - loss: 0.1614 - regularization_loss: 0.0000e+00 - total_loss: 0.1614"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 18:39:28.921898: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442/2442 [==============================] - 310s 116ms/step - auc: 0.6461 - loss: 0.1614 - regularization_loss: 0.0000e+00 - total_loss: 0.1614 - val_auc: 0.6058 - val_loss: 0.1200 - val_regularization_loss: 0.0000e+00 - val_total_loss: 0.1200\n",
      "CPU times: user 7min 51s, sys: 1min 33s, total: 9min 24s\n",
      "Wall time: 5min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecc60cbf70>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.compile('adam', run_eagerly=False)\n",
    "model.fit(train, validation_data=valid, batch_size=batch_size, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b06d60d",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd78a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as sequential_block_8_layer_call_fn, sequential_block_8_layer_call_and_return_conditional_losses, binary_classification_task_layer_call_fn, binary_classification_task_layer_call_and_return_conditional_losses, click/binary_classification_task/output_layer_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n",
      "2022-03-24 18:40:27.823089: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 788046592 exceeds 10% of free system memory.\n",
      "2022-03-24 18:40:28.426818: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 788046592 exceeds 10% of free system memory.\n",
      "2022-03-24 18:40:29.060094: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 788046592 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dlrm/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: dlrm/assets\n"
     ]
    }
   ],
   "source": [
    "model.save('dlrm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91205a3c-f46e-45a0-b668-1a9bdef0c51d",
   "metadata": {},
   "source": [
    "## Building a Retrieval Model with Two-Tower Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00de24e9-331a-486e-9843-6c554ad2ec77",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/workspace/processed/retrieval/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdaec18-84f2-42f6-bee5-d66cf28c03f4",
   "metadata": {},
   "source": [
    "We select only positive interaction rows therefore we remove rows where `click==0` from the dataset with `Filter()` op."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22a7d605-478f-40e6-a5dc-3e7a61e9b035",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n",
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "user_id = [\"user_id\"] >> Categorify() >> TagAsUserID()\n",
    "item_id = [\"item_id\"] >> Categorify() >> TagAsItemID()\n",
    "\n",
    "item_features = [\"item_category\", \"item_shop\", \"item_brand\"] >> nvt.ops.Categorify() >> AddTags(tags=[Tags.ITEM])\n",
    "\n",
    "user_features = ['user_shops', 'user_profile', 'user_group', \n",
    "       'user_gender', 'user_age', 'user_consumption_2', 'user_is_occupied',\n",
    "       'user_geography', 'user_intentions', 'user_brands', 'user_categories'] \\\n",
    "        >> nvt.ops.Categorify() >> AddTags(tags=[Tags.USER])\n",
    "\n",
    "inputs = user_id + item_id + item_features + user_features + ['click'] \n",
    "\n",
    "outputs = inputs >> Filter(f=lambda df: df[\"click\"] == 1)\n",
    "\n",
    "workflow_fit_transform(outputs, train_path, test_path, output_path, 'workflow_retrieval')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc150549-6fa0-441f-939d-a358e56d5e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/cudf/core/dataframe.py:1253: UserWarning: The deep parameter is ignored and is only included for pandas compatibility.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_tt = Dataset(os.path.join(output_path, 'train', '*.parquet'), part_size=\"500MB\")\n",
    "valid_tt = Dataset(os.path.join(output_path, 'test', '*.parquet'), part_size=\"500MB\")\n",
    "\n",
    "schema = train.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e9ed972-95b2-42f5-830e-d4e99ddb4dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02471088-0ed8-42e7-968e-b7e68865d55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModel(\n",
    "    schema,\n",
    "    query_tower=mm.MLPBlock([128, 64], no_activation_last_layer=True),        \n",
    "    loss=\"categorical_crossentropy\",  \n",
    "    samplers=[mm.InBatchSampler()],\n",
    "    embedding_options = mm.EmbeddingOptions(infer_embedding_sizes=True),\n",
    "    metrics=[mm.RecallAt(10), mm.NDCGAt(10)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6703d7c-d38f-4d6d-a20a-9ee95ff1e256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7feede06f5e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:merlin_models:The sampler InBatchSampler returned no samples for this batch.\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7feede06f5e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.Socket(zmq.PUSH) at 0x7feede06f5e0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "382/384 [============================>.] - ETA: 0s - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3226 - regularization_loss: 0.0000e+00 - total_loss: 8.3226"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_1_layer_call_fn, block_context_1_layer_call_and_return_conditional_losses, sequential_block_13_layer_call_fn, sequential_block_13_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n",
      "2022-03-24 18:41:31.056288: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxj2sh2ay/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpxj2sh2ay/assets\n",
      "2022-03-24 18:41:34.284865: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
      "2022-03-24 18:42:15.171486: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:907] Skipping loop optimization for Merge node with control input: cond/then/_0/cond/cond/branch_executed/_184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 68s 159ms/step - recall_at_10: 0.0024 - ndcg_10: 0.0011 - loss: 8.3196 - regularization_loss: 0.0000e+00 - total_loss: 8.3196 - val_recall_at_10: 0.0026 - val_ndcg_10: 0.0012 - val_loss: 7.4209 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4209\n",
      "Epoch 2/2\n",
      "384/384 [==============================] - ETA: 0s - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3199 - regularization_loss: 0.0000e+00 - total_loss: 8.3199"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_1_layer_call_fn, block_context_1_layer_call_and_return_conditional_losses, sequential_block_13_layer_call_fn, sequential_block_13_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpejxazd24/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpejxazd24/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384/384 [==============================] - 58s 151ms/step - recall_at_10: 0.0025 - ndcg_10: 0.0011 - loss: 8.3184 - regularization_loss: 0.0000e+00 - total_loss: 8.3184 - val_recall_at_10: 0.0026 - val_ndcg_10: 0.0012 - val_loss: 7.4200 - val_regularization_loss: 0.0000e+00 - val_total_loss: 7.4200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fecb2386550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.set_retrieval_candidates_for_evaluation(train)\n",
    "\n",
    "opt = tf.keras.optimizers.Adagrad(learning_rate=0.003)\n",
    "model.compile(optimizer=opt, run_eagerly=False)\n",
    "model.fit(train_tt, validation_data=valid_tt, batch_size=4096, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44fc89d-170b-41a1-a29b-5f958ed31399",
   "metadata": {},
   "source": [
    "## Exporting Retrieval Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2af24597-e89c-43a4-9a13-458d8bed7c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_1_layer_call_fn, block_context_1_layer_call_and_return_conditional_losses, sequential_block_16_layer_call_fn, sequential_block_16_layer_call_and_return_conditional_losses, l2_norm_1_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_tower/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: query_tower/assets\n"
     ]
    }
   ],
   "source": [
    "query_tower = model.retrieval_block.query_block()\n",
    "query_tower.save('query_tower')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea0b369c-2f01-42e3-9f3c-74c3ff4a6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "user_features = unique_rows_by_features(train, Tags.USER, Tags.USER_ID).compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6b0949f9-e67a-414f-9d74-65f138e820a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_shops</th>\n",
       "      <th>user_profile</th>\n",
       "      <th>user_group</th>\n",
       "      <th>user_gender</th>\n",
       "      <th>user_age</th>\n",
       "      <th>user_consumption_2</th>\n",
       "      <th>user_is_occupied</th>\n",
       "      <th>user_geography</th>\n",
       "      <th>user_intentions</th>\n",
       "      <th>user_brands</th>\n",
       "      <th>user_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>131</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>4709</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1876</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>534</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>22</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  user_shops  user_profile  user_group  user_gender  user_age  \\\n",
       "0        0           0             1           5            2         2   \n",
       "1        1         109             0           0            0         0   \n",
       "2        2         301             1           1            1         1   \n",
       "3        3        1876            23           7            2         3   \n",
       "4        4         534             1           2            1         2   \n",
       "\n",
       "   user_consumption_2  user_is_occupied  user_geography  user_intentions  \\\n",
       "0                   2                 1               0                0   \n",
       "1                   0                 0               0               69   \n",
       "2                   1                 1               2               57   \n",
       "3                   1                 1               1                5   \n",
       "4                   1                 1               0               40   \n",
       "\n",
       "   user_brands  user_categories  \n",
       "0            0                0  \n",
       "1          131                9  \n",
       "2         4709               57  \n",
       "3           63                3  \n",
       "4           22              108  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22087f21-5717-44bb-88f3-41a8ab8f85a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id               int64\n",
       "user_shops            int64\n",
       "user_profile          int64\n",
       "user_group            int64\n",
       "user_gender           int64\n",
       "user_age              int64\n",
       "user_consumption_2    int64\n",
       "user_is_occupied      int64\n",
       "user_geography        int64\n",
       "user_intentions       int64\n",
       "user_brands           int64\n",
       "user_categories       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4515052d-6dd6-412c-a7ed-e312cbded066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['user_id', 'user_shops', 'user_profile', 'user_group', 'user_gender',\n",
       "       'user_age', 'user_consumption_2', 'user_is_occupied', 'user_geography',\n",
       "       'user_intentions', 'user_brands', 'user_categories'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f5d12069-0b12-4099-a616-8fe45a701aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(294736, 12)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d30bd2f8-8a78-4df7-9bc4-42bd741c5b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "user_features[\"datetime\"] = datetime.now()\n",
    "user_features[\"datetime\"] = user_features[\"datetime\"].astype(\"datetime64[ns]\")\n",
    "user_features[\"created\"] = datetime.now()\n",
    "user_features[\"created\"] = user_features[\"created\"].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2981b3ed-6156-49f0-aa14-326a3853a58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features.to_parquet('user_features.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a33a668-8e2a-4546-8f54-0060d405ba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID).compute().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dc94f78-8bbb-42b1-9882-72ee7f450140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category</th>\n",
       "      <th>item_shop</th>\n",
       "      <th>item_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>441</td>\n",
       "      <td>432</td>\n",
       "      <td>474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>1159</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1463</td>\n",
       "      <td>872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>282</td>\n",
       "      <td>2479</td>\n",
       "      <td>555</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  item_category  item_shop  item_brand\n",
       "0        0              0          0           0\n",
       "1        1            441        432         474\n",
       "2        2            193       1159         125\n",
       "3        3              3       1463         872\n",
       "4        4            282       2479         555"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15ebac41-e6b9-44f7-8650-bc00a9bc6c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id          int64\n",
       "item_category    int64\n",
       "item_shop        int64\n",
       "item_brand       int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "97189581-473c-4928-8be7-ec31b86d69ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3078306, 4)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "68a694d6-926f-4b0f-8edc-8cc7ac85ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features[\"datetime\"] = datetime.now()\n",
    "item_features[\"datetime\"] = item_features[\"datetime\"].astype(\"datetime64[ns]\")\n",
    "item_features[\"created\"] = datetime.now()\n",
    "item_features[\"created\"] = item_features[\"created\"].astype(\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b5390df9-6faa-4fca-b038-c4756fba56ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "item_id                   int64\n",
       "item_category             int64\n",
       "item_shop                 int64\n",
       "item_brand                int64\n",
       "datetime         datetime64[ns]\n",
       "created          datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c03fa22-b112-4243-bbe1-1cd7260cb85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c312884b-a1f8-4e08-8068-696e06a9bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "item_features.to_parquet('item_features.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff30ceab-b264-4509-9c5b-5a10425e143b",
   "metadata": {},
   "source": [
    "#### Extract and save Item embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "00f1fe65-882e-4962-bb16-19a130fda215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as block_context_1_layer_call_fn, block_context_1_layer_call_and_return_conditional_losses, sequential_block_13_layer_call_fn, sequential_block_13_layer_call_and_return_conditional_losses, l2_norm_layer_call_fn while saving (showing 5 of 26). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmhpp3f_e/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpmhpp3f_e/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "item_embs = model.item_embeddings(Dataset(item_features, schema=schema), batch_size=1024)\n",
    "item_embs_df = item_embs.compute(scheduler=\"synchronous\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cf8b82ea-6cce-4dab-ad17-114b5e7eabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only embedding columns\n",
    "item_embeddings = item_embs_df.iloc[:, 4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e02f0957-6665-400a-80c0-60b307466caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.240219</td>\n",
       "      <td>0.098013</td>\n",
       "      <td>0.084337</td>\n",
       "      <td>0.031100</td>\n",
       "      <td>0.104367</td>\n",
       "      <td>0.045661</td>\n",
       "      <td>0.020319</td>\n",
       "      <td>0.153839</td>\n",
       "      <td>0.161770</td>\n",
       "      <td>0.107052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121493</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.094518</td>\n",
       "      <td>0.092909</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.044954</td>\n",
       "      <td>0.202433</td>\n",
       "      <td>0.001573</td>\n",
       "      <td>0.005804</td>\n",
       "      <td>-0.083102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.036755</td>\n",
       "      <td>0.225635</td>\n",
       "      <td>-0.104459</td>\n",
       "      <td>-0.086914</td>\n",
       "      <td>0.100140</td>\n",
       "      <td>0.118539</td>\n",
       "      <td>-0.090942</td>\n",
       "      <td>0.049130</td>\n",
       "      <td>0.242738</td>\n",
       "      <td>0.154544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.263599</td>\n",
       "      <td>0.091065</td>\n",
       "      <td>0.030586</td>\n",
       "      <td>-0.024852</td>\n",
       "      <td>-0.089785</td>\n",
       "      <td>0.167049</td>\n",
       "      <td>-0.036791</td>\n",
       "      <td>0.087586</td>\n",
       "      <td>-0.109924</td>\n",
       "      <td>-0.129684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.243588</td>\n",
       "      <td>0.090928</td>\n",
       "      <td>0.021481</td>\n",
       "      <td>0.127052</td>\n",
       "      <td>-0.061280</td>\n",
       "      <td>0.090714</td>\n",
       "      <td>0.106807</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.241243</td>\n",
       "      <td>0.020420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207998</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>-0.282395</td>\n",
       "      <td>0.022748</td>\n",
       "      <td>-0.179967</td>\n",
       "      <td>-0.136605</td>\n",
       "      <td>0.132614</td>\n",
       "      <td>-0.036602</td>\n",
       "      <td>0.240175</td>\n",
       "      <td>0.093345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.160735</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>-0.068275</td>\n",
       "      <td>-0.015373</td>\n",
       "      <td>0.125100</td>\n",
       "      <td>0.148184</td>\n",
       "      <td>-0.064653</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>-0.051233</td>\n",
       "      <td>0.210893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166989</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>-0.079048</td>\n",
       "      <td>0.106997</td>\n",
       "      <td>-0.023781</td>\n",
       "      <td>0.167731</td>\n",
       "      <td>-0.114966</td>\n",
       "      <td>-0.052225</td>\n",
       "      <td>-0.161464</td>\n",
       "      <td>-0.138233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.044245</td>\n",
       "      <td>0.171201</td>\n",
       "      <td>-0.008067</td>\n",
       "      <td>0.048566</td>\n",
       "      <td>-0.148960</td>\n",
       "      <td>0.023509</td>\n",
       "      <td>-0.013836</td>\n",
       "      <td>0.056129</td>\n",
       "      <td>0.312029</td>\n",
       "      <td>-0.116087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221192</td>\n",
       "      <td>-0.033822</td>\n",
       "      <td>-0.076613</td>\n",
       "      <td>-0.138665</td>\n",
       "      <td>-0.221075</td>\n",
       "      <td>-0.067987</td>\n",
       "      <td>0.029779</td>\n",
       "      <td>0.184153</td>\n",
       "      <td>0.200796</td>\n",
       "      <td>-0.025561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078301</th>\n",
       "      <td>-0.127434</td>\n",
       "      <td>0.234514</td>\n",
       "      <td>0.033737</td>\n",
       "      <td>0.114038</td>\n",
       "      <td>-0.170819</td>\n",
       "      <td>0.085047</td>\n",
       "      <td>0.121316</td>\n",
       "      <td>0.106980</td>\n",
       "      <td>0.268950</td>\n",
       "      <td>0.072199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120395</td>\n",
       "      <td>-0.113239</td>\n",
       "      <td>0.157824</td>\n",
       "      <td>0.116763</td>\n",
       "      <td>-0.052521</td>\n",
       "      <td>0.032848</td>\n",
       "      <td>-0.010210</td>\n",
       "      <td>-0.031877</td>\n",
       "      <td>0.021030</td>\n",
       "      <td>0.072824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078302</th>\n",
       "      <td>-0.001478</td>\n",
       "      <td>0.322349</td>\n",
       "      <td>-0.017481</td>\n",
       "      <td>-0.122504</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.098336</td>\n",
       "      <td>0.035148</td>\n",
       "      <td>-0.077741</td>\n",
       "      <td>0.198080</td>\n",
       "      <td>-0.164761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262214</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.180257</td>\n",
       "      <td>-0.069942</td>\n",
       "      <td>-0.149382</td>\n",
       "      <td>0.134342</td>\n",
       "      <td>0.043282</td>\n",
       "      <td>0.077701</td>\n",
       "      <td>-0.048704</td>\n",
       "      <td>-0.029332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078303</th>\n",
       "      <td>-0.095164</td>\n",
       "      <td>0.051032</td>\n",
       "      <td>-0.096254</td>\n",
       "      <td>0.015315</td>\n",
       "      <td>-0.069524</td>\n",
       "      <td>0.099273</td>\n",
       "      <td>-0.039192</td>\n",
       "      <td>0.158641</td>\n",
       "      <td>0.295329</td>\n",
       "      <td>-0.067302</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167899</td>\n",
       "      <td>0.100052</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>-0.131238</td>\n",
       "      <td>-0.189871</td>\n",
       "      <td>-0.080607</td>\n",
       "      <td>0.100726</td>\n",
       "      <td>0.014591</td>\n",
       "      <td>0.111981</td>\n",
       "      <td>-0.011644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078304</th>\n",
       "      <td>-0.123624</td>\n",
       "      <td>0.173730</td>\n",
       "      <td>0.060116</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>-0.076002</td>\n",
       "      <td>0.146545</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.101340</td>\n",
       "      <td>0.099717</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014092</td>\n",
       "      <td>-0.088312</td>\n",
       "      <td>0.018992</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>-0.126568</td>\n",
       "      <td>-0.138310</td>\n",
       "      <td>0.115050</td>\n",
       "      <td>-0.082769</td>\n",
       "      <td>0.190359</td>\n",
       "      <td>-0.071905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3078305</th>\n",
       "      <td>-0.213872</td>\n",
       "      <td>0.188533</td>\n",
       "      <td>0.113784</td>\n",
       "      <td>-0.003590</td>\n",
       "      <td>-0.139653</td>\n",
       "      <td>0.035523</td>\n",
       "      <td>-0.111347</td>\n",
       "      <td>0.066931</td>\n",
       "      <td>0.072708</td>\n",
       "      <td>-0.084013</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241125</td>\n",
       "      <td>-0.020729</td>\n",
       "      <td>-0.058368</td>\n",
       "      <td>0.023252</td>\n",
       "      <td>-0.056942</td>\n",
       "      <td>0.113739</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.127162</td>\n",
       "      <td>0.039191</td>\n",
       "      <td>-0.049049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3078306 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0         1         2         3         4         5         6  \\\n",
       "0       -0.240219  0.098013  0.084337  0.031100  0.104367  0.045661  0.020319   \n",
       "1        0.036755  0.225635 -0.104459 -0.086914  0.100140  0.118539 -0.090942   \n",
       "2       -0.243588  0.090928  0.021481  0.127052 -0.061280  0.090714  0.106807   \n",
       "3        0.160735  0.022391 -0.068275 -0.015373  0.125100  0.148184 -0.064653   \n",
       "4       -0.044245  0.171201 -0.008067  0.048566 -0.148960  0.023509 -0.013836   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3078301 -0.127434  0.234514  0.033737  0.114038 -0.170819  0.085047  0.121316   \n",
       "3078302 -0.001478  0.322349 -0.017481 -0.122504  0.096282  0.098336  0.035148   \n",
       "3078303 -0.095164  0.051032 -0.096254  0.015315 -0.069524  0.099273 -0.039192   \n",
       "3078304 -0.123624  0.173730  0.060116  0.008632 -0.076002  0.146545  0.003808   \n",
       "3078305 -0.213872  0.188533  0.113784 -0.003590 -0.139653  0.035523 -0.111347   \n",
       "\n",
       "                7         8         9  ...        54        55        56  \\\n",
       "0        0.153839  0.161770  0.107052  ...  0.121493 -0.000128 -0.094518   \n",
       "1        0.049130  0.242738  0.154544  ...  0.263599  0.091065  0.030586   \n",
       "2        0.065844  0.241243  0.020420  ...  0.207998 -0.010261 -0.282395   \n",
       "3        0.038877 -0.051233  0.210893  ...  0.166989 -0.000811 -0.079048   \n",
       "4        0.056129  0.312029 -0.116087  ...  0.221192 -0.033822 -0.076613   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3078301  0.106980  0.268950  0.072199  ...  0.120395 -0.113239  0.157824   \n",
       "3078302 -0.077741  0.198080 -0.164761  ...  0.262214 -0.177650 -0.180257   \n",
       "3078303  0.158641  0.295329 -0.067302  ...  0.167899  0.100052  0.088500   \n",
       "3078304  0.101340  0.099717  0.014800  ...  0.014092 -0.088312  0.018992   \n",
       "3078305  0.066931  0.072708 -0.084013  ...  0.241125 -0.020729 -0.058368   \n",
       "\n",
       "               57        58        59        60        61        62        63  \n",
       "0        0.092909  0.088235  0.044954  0.202433  0.001573  0.005804 -0.083102  \n",
       "1       -0.024852 -0.089785  0.167049 -0.036791  0.087586 -0.109924 -0.129684  \n",
       "2        0.022748 -0.179967 -0.136605  0.132614 -0.036602  0.240175  0.093345  \n",
       "3        0.106997 -0.023781  0.167731 -0.114966 -0.052225 -0.161464 -0.138233  \n",
       "4       -0.138665 -0.221075 -0.067987  0.029779  0.184153  0.200796 -0.025561  \n",
       "...           ...       ...       ...       ...       ...       ...       ...  \n",
       "3078301  0.116763 -0.052521  0.032848 -0.010210 -0.031877  0.021030  0.072824  \n",
       "3078302 -0.069942 -0.149382  0.134342  0.043282  0.077701 -0.048704 -0.029332  \n",
       "3078303 -0.131238 -0.189871 -0.080607  0.100726  0.014591  0.111981 -0.011644  \n",
       "3078304 -0.050800 -0.126568 -0.138310  0.115050 -0.082769  0.190359 -0.071905  \n",
       "3078305  0.023252 -0.056942  0.113739 -0.021246  0.127162  0.039191 -0.049049  \n",
       "\n",
       "[3078306 rows x 64 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66d7271e-0ea6-4568-ac5a-04089735f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "item_embeddings.to_parquet('item_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ffd36-edd1-47ad-89e6-5c5daf270dc5",
   "metadata": {},
   "source": [
    "## Deploying the Model into Production with Merlin Systems and Triton IS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b267f2-1d27-476c-b0cc-5564b429b5e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nvtabular/nvtabular/graph.py:23: FutureWarning: The `nvtabular.graph` module has moved to `merlin.dag`. Support for importing from `nvtabular.graph` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.dag`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/io.py:23: FutureWarning: The `nvtabular.io` module has moved to `merlin.io`. Support for importing from `nvtabular.io` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.io`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/utils.py:23: FutureWarning: The `nvtabular.utils` module has moved to `merlin.core.utils`. Support for importing from `nvtabular.utils` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.utils`.\n",
      "  warnings.warn(\n",
      "/nvtabular/nvtabular/dispatch.py:23: FutureWarning: The `nvtabular.dispatch` module has moved to `merlin.core.dispatch`. Support for importing from `nvtabular.dispatch` is deprecated, and will be removed in a future version. Please update your imports to import from `merlin.core.dispatch`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.dlpack.dlpack.from_dlpack(dlcapsule)>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nvtabular.loader.tf_utils import configure_tensorflow, get_dataset_schema_from_feature_columns\n",
    "\n",
    "configure_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7987c79b-6c83-4fd0-b78a-b29fd7f04f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ[\"TF_MEMORY_ALLOCATION\"]=\"0.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ba59b5-08c3-44b5-86f2-e63dec6893af",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"/models/examples\"\n",
    "faiss_index_path = './tmp' + \"/index.faiss\"\n",
    "feast_repo_path = base_path + \"/feature_repo/\"\n",
    "retrieval_model_path = base_path + \"/query_tower/\"\n",
    "ranking_model_path = base_path + \"/dlrm/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7103033-1860-4857-ab6e-99b9581b24ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tmp/index.faiss',\n",
       " '/models/examples/feature_repo/',\n",
       " '/models/examples/query_tower/')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "faiss_index_path, feast_repo_path, retrieval_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf19ea98-55b4-49fd-af0c-70b3fc5bb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular import ColumnSchema, Schema\n",
    "\n",
    "from merlin.systems.dag.ensemble import Ensemble\n",
    "from merlin.systems.dag.ops.session_filter import FilterCandidates\n",
    "from merlin.systems.dag.ops.softmax_sampling import SoftmaxSampling\n",
    "from merlin.systems.dag.ops.tensorflow import PredictTensorflow\n",
    "from merlin.systems.dag.ops.unroll_features import UnrollFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffc3327f-20cd-4d66-91c8-389e5dd0529a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_ensemble_triton import _run_ensemble_on_tritonserver\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3eac635d-f029-480e-9b0c-d1d9b26c6ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/faiss/loader.py:28: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numpy.__version__) >= \"1.19\":\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "03/24/2022 10:27:15 PM INFO:Loading faiss with AVX2 support.\n",
      "03/24/2022 10:27:15 PM INFO:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "03/24/2022 10:27:15 PM INFO:Loading faiss.\n",
      "03/24/2022 10:27:15 PM INFO:Successfully loaded faiss.\n",
      "/systems/merlin/systems/dag/ops/feast.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ValueType.FLOAT: (np.float, False, False),\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cudf\n",
    "import feast\n",
    "import faiss\n",
    "\n",
    "from merlin.systems.dag.ops.faiss import QueryFaiss, setup_faiss \n",
    "from merlin.systems.dag.ops.feast import QueryFeast \n",
    "\n",
    "\n",
    "request_schema = Schema(\n",
    "    [\n",
    "        ColumnSchema(\"user_id\", dtype=np.int64),\n",
    "    ]\n",
    ")\n",
    "\n",
    "item_embeddings = np.ascontiguousarray(\n",
    "    pd.read_parquet(base_path + \"/item_embeddings.parquet\").to_numpy()\n",
    ")\n",
    "\n",
    "feature_store = feast.FeatureStore(feast_repo_path)\n",
    "setup_faiss(item_embeddings, str(faiss_index_path))\n",
    "\n",
    "user_features = [\"user_id\"] >> QueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    path=feast_repo_path,\n",
    "    view=\"user_features\",\n",
    "    column=\"user_id\",\n",
    "    include_id=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c2d9b1-51dc-4549-977d-d7941ee6486c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-24 22:27:20.329563: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-24 22:27:21.732087: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 16254 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2022-03-24 22:27:23.928631: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1034311152 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "03/24/2022 10:27:24 PM WARNING:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "retrieval = (\n",
    "    user_features\n",
    "    >> PredictTensorflow(retrieval_model_path)\n",
    "    >> QueryFaiss(faiss_index_path, topk=100)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b270f663-0ae1-4356-acd4-5f8c986abf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_features = retrieval[\"candidate_ids\"] >> QueryFeast.from_feature_view(\n",
    "    store=feature_store,\n",
    "    path=feast_repo_path,\n",
    "    view=\"item_features\",\n",
    "    column=\"candidate_ids\",\n",
    "    output_prefix=\"item\",\n",
    "    include_id=True,\n",
    ")\n",
    "\n",
    "user_features_to_unroll = [\n",
    "    \"user_id\",\n",
    "    \"user_shops\",\n",
    "    \"user_profile\",\n",
    "    \"user_group\",\n",
    "    \"user_gender\",\n",
    "    \"user_age\",\n",
    "    \"user_consumption_2\",\n",
    "    \"user_is_occupied\",\n",
    "    \"user_geography\",\n",
    "    \"user_intentions\",\n",
    "    \"user_brands\",\n",
    "    \"user_categories\",\n",
    "]\n",
    "combined_features = item_features >> UnrollFeatures(\n",
    "    \"item_id\", user_features[user_features_to_unroll]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce31723e-af4d-4827-bb60-3a9fafcd9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = combined_features >> PredictTensorflow(ranking_model_path)\n",
    "\n",
    "ordering = combined_features[\"item_id\"] >> SoftmaxSampling(\n",
    "    relevance_col=ranking[\"output_1\"], topk=10, temperature=20.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7896ec0-db89-4642-bfb6-eebf9afe77ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_path = str(\"./test_poc\")\n",
    "\n",
    "ensemble = Ensemble(ordering, request_schema)\n",
    "ens_config, node_configs = ensemble.export(export_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dab9b6f1-d576-43e3-83c2-89017f88d3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0324 22:27:44.104774 1676 tensorflow.cc:2176] TRITONBACKEND_Initialize: tensorflow\n",
      "I0324 22:27:44.104855 1676 tensorflow.cc:2186] Triton TRITONBACKEND API version: 1.8\n",
      "I0324 22:27:44.104859 1676 tensorflow.cc:2192] 'tensorflow' TRITONBACKEND API version: 1.8\n",
      "I0324 22:27:44.104863 1676 tensorflow.cc:2216] backend configuration:\n",
      "{\"cmdline\":{\"version\":\"2\"}}\n",
      "I0324 22:27:44.248887 1676 pinned_memory_manager.cc:240] Pinned memory pool is created at '0x7f64d8000000' with size 268435456\n",
      "I0324 22:27:44.249253 1676 cuda_memory_manager.cc:105] CUDA memory pool is created on device 0 with size 67108864\n",
      "I0324 22:27:44.254555 1676 model_repository_manager.cc:994] loading: 0_queryfeast:1\n",
      "I0324 22:27:44.355003 1676 model_repository_manager.cc:994] loading: 1_predicttensorflow:1\n",
      "I0324 22:27:44.358371 1676 backend.cc:46] TRITONBACKEND_Initialize: nvtabular\n",
      "I0324 22:27:44.358406 1676 backend.cc:53] Triton TRITONBACKEND API version: 1.8\n",
      "I0324 22:27:44.358418 1676 backend.cc:56] 'nvtabular' TRITONBACKEND API version: 1.8\n",
      "I0324 22:27:44.358639 1676 backend.cc:76] Loaded libpython successfully\n",
      "I0324 22:27:44.455253 1676 model_repository_manager.cc:994] loading: 2_queryfaiss:1\n",
      "I0324 22:27:44.526418 1676 backend.cc:89] Python interpreter is initialized\n",
      "I0324 22:27:44.527638 1676 tensorflow.cc:2276] TRITONBACKEND_ModelInitialize: 1_predicttensorflow (version 1)\n",
      "I0324 22:27:44.555652 1676 model_repository_manager.cc:994] loading: 3_queryfeast:1\n",
      "I0324 22:27:44.560607 1676 model_inst_state.hpp:64] Loading TritonPythonnModel from model.py in path './test_poc/0_queryfeast/1'\n",
      "I0324 22:27:44.656122 1676 model_repository_manager.cc:994] loading: 4_unrollfeatures:1\n",
      "I0324 22:27:44.756598 1676 model_repository_manager.cc:994] loading: 5_predicttensorflow:1\n",
      "I0324 22:27:44.856960 1676 model_repository_manager.cc:994] loading: 6_softmaxsampling:1\n",
      "I0324 22:27:46.619643 1676 tensorflow.cc:2325] TRITONBACKEND_ModelInstanceInitialize: 1_predicttensorflow (GPU device 0)\n",
      "I0324 22:27:46.620161 1676 model_repository_manager.cc:1149] successfully loaded '0_queryfeast' version 1\n",
      "2022-03-24 22:27:48.060971: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./test_poc/1_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:48.065498: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-03-24 22:27:48.065536: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: ./test_poc/1_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:48.071535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2022-03-24 22:27:48.119173: I tensorflow/cc/saved_model/loader.cc:212] Restoring SavedModel bundle.\n",
      "2022-03-24 22:27:49.023014: I tensorflow/cc/saved_model/loader.cc:196] Running initialization op on SavedModel bundle at path: ./test_poc/1_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:49.059938: I tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 998985 microseconds.\n",
      "I0324 22:27:49.060157 1676 model_inst_state.hpp:64] Loading TritonPythonnModel from model.py in path './test_poc/2_queryfaiss/1'I0324 22:27:49.060178 1676 model_repository_manager.cc:1149] successfully loaded '1_predicttensorflow' version 1\n",
      "\n",
      "/systems/merlin/systems/dag/ops/feast.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ValueType.FLOAT: (np.float, False, False),\n",
      "/usr/local/lib/python3.8/dist-packages/faiss/loader.py:28: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numpy.__version__) >= \"1.19\":\n",
      "/usr/local/lib/python3.8/dist-packages/setuptools/_distutils/version.py:351: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  other = LooseVersion(other)\n",
      "03/24/2022 10:27:49 PM INFO:Loading faiss with AVX2 support.\n",
      "03/24/2022 10:27:49 PM INFO:Could not load library with AVX2 support due to:\n",
      "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
      "03/24/2022 10:27:49 PM INFO:Loading faiss.\n",
      "03/24/2022 10:27:49 PM INFO:Successfully loaded faiss.\n",
      "I0324 22:27:49.529646 1676 model_repository_manager.cc:1149] successfully loaded '2_queryfaiss' version 1\n",
      "I0324 22:27:49.531309 1676 tensorflow.cc:2276] TRITONBACKEND_ModelInitialize: 5_predicttensorflow (version 1)\n",
      "I0324 22:27:49.533671 1676 model_inst_state.hpp:64] Loading TritonPythonnModel from model.py in path './test_poc/3_queryfeast/1'\n",
      "I0324 22:27:49.542628 1676 model_repository_manager.cc:1149] successfully loaded '3_queryfeast' version 1\n",
      "I0324 22:27:49.542948 1676 model_inst_state.hpp:64] Loading TritonPythonnModel from model.py in path './test_poc/4_unrollfeatures/1'\n",
      "I0324 22:27:49.548825 1676 tensorflow.cc:2325] TRITONBACKEND_ModelInstanceInitialize: 5_predicttensorflow (GPU device 0)\n",
      "I0324 22:27:49.548877 1676 model_repository_manager.cc:1149] successfully loaded '4_unrollfeatures' version 1\n",
      "2022-03-24 22:27:49.549447: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: ./test_poc/5_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:49.573332: I tensorflow/cc/saved_model/reader.cc:107] Reading meta graph with tags { serve }\n",
      "2022-03-24 22:27:49.573374: I tensorflow/cc/saved_model/reader.cc:148] Reading SavedModel debug info (if present) from: ./test_poc/5_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:49.578354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13584 MB memory:  -> device: 0, name: Quadro GV100, pci bus id: 0000:15:00.0, compute capability: 7.0\n",
      "2022-03-24 22:27:49.614581: I tensorflow/cc/saved_model/loader.cc:212] Restoring SavedModel bundle.\n",
      "2022-03-24 22:27:50.793203: I tensorflow/cc/saved_model/loader.cc:196] Running initialization op on SavedModel bundle at path: ./test_poc/5_predicttensorflow/1/model.savedmodel\n",
      "2022-03-24 22:27:50.871294: I tensorflow/cc/saved_model/loader.cc:303] SavedModel load for tags { serve }; Status: success: OK. Took 1321860 microseconds.\n",
      "I0324 22:27:50.871475 1676 model_inst_state.hpp:64] Loading TritonPythonnModel from model.py in path './test_poc/6_softmaxsampling/1'\n",
      "I0324 22:27:50.871525 1676 model_repository_manager.cc:1149] successfully loaded '5_predicttensorflow' version 1\n",
      "I0324 22:27:50.872850 1676 model_repository_manager.cc:1149] successfully loaded '6_softmaxsampling' version 1\n",
      "W0324 22:27:50.884534 1676 model_repository_manager.cc:203] ignore version directory '.ipynb_checkpoints' which fails to convert to integral number\n",
      "I0324 22:27:50.884662 1676 model_repository_manager.cc:994] loading: ensemble_model:1\n",
      "I0324 22:27:50.985465 1676 model_repository_manager.cc:1149] successfully loaded 'ensemble_model' version 1\n",
      "I0324 22:27:50.985635 1676 server.cc:522] \n",
      "+------------------+------+\n",
      "| Repository Agent | Path |\n",
      "+------------------+------+\n",
      "+------------------+------+\n",
      "\n",
      "I0324 22:27:50.985739 1676 server.cc:549] \n",
      "+------------+-----------------------------------------------------------------+-----------------------------+\n",
      "| Backend    | Path                                                            | Config                      |\n",
      "+------------+-----------------------------------------------------------------+-----------------------------+\n",
      "| tensorflow | /opt/tritonserver/backends/tensorflow2/libtriton_tensorflow2.so | {\"cmdline\":{\"version\":\"2\"}} |\n",
      "| nvtabular  | /opt/tritonserver/backends/nvtabular/libtriton_nvtabular.so     | {}                          |\n",
      "+------------+-----------------------------------------------------------------+-----------------------------+\n",
      "\n",
      "I0324 22:27:50.985901 1676 server.cc:592] \n",
      "+---------------------+---------+--------+\n",
      "| Model               | Version | Status |\n",
      "+---------------------+---------+--------+\n",
      "| 0_queryfeast        | 1       | READY  |\n",
      "| 1_predicttensorflow | 1       | READY  |\n",
      "| 2_queryfaiss        | 1       | READY  |\n",
      "| 3_queryfeast        | 1       | READY  |\n",
      "| 4_unrollfeatures    | 1       | READY  |\n",
      "| 5_predicttensorflow | 1       | READY  |\n",
      "| 6_softmaxsampling   | 1       | READY  |\n",
      "| ensemble_model      | 1       | READY  |\n",
      "+---------------------+---------+--------+\n",
      "\n",
      "I0324 22:27:51.067054 1676 metrics.cc:623] Collecting metrics for GPU 0: Quadro GV100\n",
      "I0324 22:27:51.067426 1676 tritonserver.cc:1932] \n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| Option                           | Value                                                                                                                                                                                        |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "| server_id                        | triton                                                                                                                                                                                       |\n",
      "| server_version                   | 2.19.0                                                                                                                                                                                       |\n",
      "| server_extensions                | classification sequence model_repository model_repository(unload_dependents) schedule_policy model_configuration system_shared_memory cuda_shared_memory binary_tensor_data statistics trace |\n",
      "| model_repository_path[0]         | ./test_poc                                                                                                                                                                                   |\n",
      "| model_control_mode               | MODE_NONE                                                                                                                                                                                    |\n",
      "| strict_model_config              | 1                                                                                                                                                                                            |\n",
      "| rate_limit                       | OFF                                                                                                                                                                                          |\n",
      "| pinned_memory_pool_byte_size     | 268435456                                                                                                                                                                                    |\n",
      "| cuda_memory_pool_byte_size{0}    | 67108864                                                                                                                                                                                     |\n",
      "| response_cache_byte_size         | 0                                                                                                                                                                                            |\n",
      "| min_supported_compute_capability | 6.0                                                                                                                                                                                          |\n",
      "| strict_readiness                 | 1                                                                                                                                                                                            |\n",
      "| exit_timeout                     | 30                                                                                                                                                                                           |\n",
      "+----------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n",
      "I0324 22:27:51.077428 1676 grpc_server.cc:4375] Started GRPCInferenceService at 0.0.0.0:8001\n",
      "I0324 22:27:51.078715 1676 http_server.cc:3075] Started HTTPService at 0.0.0.0:8000\n",
      "I0324 22:27:51.121290 1676 http_server.cc:178] Started Metrics Service at 0.0.0.0:8002\n",
      "03/24/2022 10:27:58 PM WARNING:Operator name: 0_queryfeast Start time: 1648160878.892656 End time: 1648160878.9005651\n",
      "03/24/2022 10:27:59 PM WARNING:Operator name: 2_queryfaiss Start time: 1648160879.6219683 End time: 1648160879.8039007\n",
      "03/24/2022 10:27:59 PM WARNING:Operator name: 3_queryfeast Start time: 1648160879.8042064 End time: 1648160879.8331196\n",
      "03/24/2022 10:27:59 PM WARNING:Operator name: 4_unrollfeatures Start time: 1648160879.8334663 End time: 1648160879.8343043\n",
      "03/24/2022 10:27:59 PM WARNING:Operator name: 6_softmaxsampling Start time: 1648160879.9924326 End time: 1648160879.9930441\n",
      "I0324 22:27:59.995203 1676 server.cc:252] Waiting for in-flight requests to complete.\n",
      "I0324 22:27:59.995231 1676 model_repository_manager.cc:1026] unloading: ensemble_model:1\n",
      "I0324 22:27:59.995368 1676 model_repository_manager.cc:1026] unloading: 6_softmaxsampling:1\n",
      "I0324 22:27:59.995476 1676 model_repository_manager.cc:1026] unloading: 5_predicttensorflow:1\n",
      "I0324 22:27:59.995582 1676 model_repository_manager.cc:1132] successfully unloaded 'ensemble_model' version 1\n",
      "I0324 22:27:59.995667 1676 model_repository_manager.cc:1026] unloading: 4_unrollfeatures:1\n",
      "I0324 22:27:59.995685 1676 backend.cc:160] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "Signal (11) received.\n",
      "I0324 22:27:59.995719 1676 model_repository_manager.cc:1026] unloading: 3_queryfeast:1\n",
      "I0324 22:27:59.995762 1676 model_repository_manager.cc:1026] unloading: 2_queryfaiss:1\n",
      "I0324 22:27:59.995848 1676 backend.cc:160] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "Signal (11) received.\n",
      "I0324 22:27:59.995899 1676 model_repository_manager.cc:1026] unloading: 1_predicttensorflow:1\n",
      "I0324 22:27:59.995988 1676 model_repository_manager.cc:1026] unloading: 0_queryfeast:1\n",
      "I0324 22:27:59.995999 1676 tensorflow.cc:2363] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0324 22:27:59.996037 1676 backend.cc:160] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0324 22:27:59.996075 1676 backend.cc:160] TRITONBACKEND_ModelInstanceFinalize: delete instance stateSignal (11I0324 22:27:59.996074 1676 server.cc:267] Timeout 30: Found 7 live models and 0 in-flight non-inference requests\n",
      "I0324 22:27:59.996145 1676 tensorflow.cc:2302] TRITONBACKEND_ModelFinalize: delete model state\n",
      "\n",
      ") received.\n",
      "I0324 22:27:59.996200 1676 backend.cc:160] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "I0324 22:27:59.996227 1676 tensorflow.cc:2363] TRITONBACKEND_ModelInstanceFinalize: delete instance state\n",
      "Signal (11Signal (11) received.\n",
      ") received.\n",
      "I0324 22:27:59.996347 1676 tensorflow.cc:2302] TRITONBACKEND_ModelFinalize: delete model state\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal (2) received.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0324 22:28:01.013929 1676 server.cc:267] Timeout 29: Found 7 live models and 0 in-flight non-inference requests\n",
      "I0324 22:28:02.048991 1676 server.cc:267] Timeout 28: Found 7 live models and 0 in-flight non-inference requests\n",
      "I0324 22:28:03.074960 1676 server.cc:267] Timeout 27: Found 7 live models and 0 in-flight non-inference requests\n",
      " 0# 0x0000559BD7E6B299 in /opt/tritonserver/bin/tritonserver\n",
      " 1# 0x00007F656DC9F210 in /usr/lib/x86_64-linux-gnu/libc.so.6\n",
      " 2# 0x00007F65114F1F2E in /usr/lib/x86_64-linux-gnu/libpython3.8.so.1.0\n",
      " 3# TRITONBACKEND_ModelInstanceFinalize in /opt/tritonserver/backends/nvtabular/libtriton_nvtabular.so\n",
      " 4# 0x00007F656E83CFC4 in /opt/tritonserver/bin/../lib/libtritonserver.so\n",
      " 5# 0x00007F656E8363B9 in /opt/tritonserver/bin/../lib/libtritonserver.so\n",
      " 6# 0x00007F656E836B1D in /opt/tritonserver/bin/../lib/libtritonserver.so\n",
      " 7# 0x00007F656E6BA0D7 in /opt/tritonserver/bin/../lib/libtritonserver.so\n",
      " 8# 0x00007F656E08DDE4 in /usr/lib/x86_64-linux-gnu/libstdc++.so.6\n",
      " 9# 0x00007F656E50B609 in /usr/lib/x86_64-linux-gnu/libpthread.so.0\n",
      "10# clone in /usr/lib/x86_64-linux-gnu/libc.so.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from merlin.core.dispatch import make_df\n",
    "request = make_df({\"user_id\": [1]})\n",
    "request[\"user_id\"] = request[\"user_id\"].astype(np.int64)\n",
    "\n",
    "response = _run_ensemble_on_tritonserver(\n",
    "    export_path, ensemble.graph.output_schema.column_names, request, \"ensemble_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "583e6354-183a-4dae-8533-bfc643d4452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output= response.as_numpy('ordered_ids')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdc20b8f-079c-40a4-a3e8-1bae2d4016cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 692064],\n",
       "       [ 917011],\n",
       "       [1903152],\n",
       "       [2711317],\n",
       "       [1864711],\n",
       "       [ 332748],\n",
       "       [2036044],\n",
       "       [2639642],\n",
       "       [2510817],\n",
       "       [1556993]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
